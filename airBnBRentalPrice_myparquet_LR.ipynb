{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Start Spark Session</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession, SQLContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.master('local').appName('Airbnb Rental price').getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Data Ingestion and Exploration</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- summary: string (nullable = true)\n",
      " |-- space: string (nullable = true)\n",
      " |-- description: string (nullable = true)\n",
      " |-- neighborhood_overview: string (nullable = true)\n",
      " |-- transit: string (nullable = true)\n",
      " |-- access: string (nullable = true)\n",
      " |-- house_rules: string (nullable = true)\n",
      " |-- host_since: string (nullable = true)\n",
      " |-- host_response_time: integer (nullable = true)\n",
      " |-- host_response_rate: double (nullable = true)\n",
      " |-- host_is_superhost: string (nullable = true)\n",
      " |-- host_neighbourhood: string (nullable = true)\n",
      " |-- host_total_listings_count: double (nullable = true)\n",
      " |-- host_verifications: string (nullable = true)\n",
      " |-- host_has_profile_pic: string (nullable = true)\n",
      " |-- host_identity_verified: string (nullable = true)\n",
      " |-- neighbourhood_cleansed: string (nullable = true)\n",
      " |-- zipcode: string (nullable = true)\n",
      " |-- room_type: string (nullable = true)\n",
      " |-- accommodates: double (nullable = true)\n",
      " |-- bathrooms: double (nullable = true)\n",
      " |-- bedrooms: double (nullable = true)\n",
      " |-- beds: double (nullable = true)\n",
      " |-- amenities: string (nullable = true)\n",
      " |-- price: double (nullable = true)\n",
      " |-- security_deposit: double (nullable = true)\n",
      " |-- cleaning_fee: double (nullable = true)\n",
      " |-- guests_included: double (nullable = true)\n",
      " |-- extra_people: double (nullable = true)\n",
      " |-- number_of_reviews: double (nullable = true)\n",
      " |-- number_of_reviews_ltm: double (nullable = true)\n",
      " |-- review_scores_rating: double (nullable = true)\n",
      " |-- review_scores_accuracy: double (nullable = true)\n",
      " |-- review_scores_cleanliness: double (nullable = true)\n",
      " |-- review_scores_checkin: double (nullable = true)\n",
      " |-- review_scores_communication: double (nullable = true)\n",
      " |-- review_scores_location: double (nullable = true)\n",
      " |-- review_scores_value: double (nullable = true)\n",
      " |-- license: string (nullable = true)\n",
      " |-- instant_bookable: string (nullable = true)\n",
      " |-- cancellation_policy: string (nullable = true)\n",
      " |-- require_guest_profile_picture: string (nullable = true)\n",
      " |-- require_guest_phone_verification: string (nullable = true)\n",
      " |-- calculated_host_listings_count: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "filepath = 'data/sf-airbnb/parquet'\n",
    "airbnbDF = spark.read.parquet(filepath)\n",
    "\n",
    "airbnbDF.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For now, I deleted some columns with text\n",
    "\n",
    "remove_cols = ['summary', 'space', 'description', 'neighborhood_overview', 'transit', 'access'\n",
    "                , 'house_rules', 'host_since', 'host_response_time', 'host_response_rate'\n",
    "                , 'host_neighbourhood', 'host_verifications', 'zipcode'\n",
    "                , 'neighbourhood_cleansed', 'amenities', 'security_deposit', 'cleaning_fee'\n",
    "                , 'guests_included', 'extra_people', 'number_of_reviews', 'license']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(host_is_superhost='t', host_total_listings_count=1.0, host_has_profile_pic='t', host_identity_verified='t', room_type='Entire home/apt', accommodates=3.0, bathrooms=1.0, bedrooms=1.0, beds=2.0, price=170.0, number_of_reviews_ltm=52.0, review_scores_rating=97.0, review_scores_accuracy=10.0, review_scores_cleanliness=10.0, review_scores_checkin=10.0, review_scores_communication=10.0, review_scores_location=10.0, review_scores_value=10.0, instant_bookable='t', cancellation_policy='moderate', require_guest_profile_picture='f', require_guest_phone_verification='f', calculated_host_listings_count=1.0)]"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = airbnbDF.drop(*remove_cols)\n",
    "\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- host_is_superhost: string (nullable = true)\n",
      " |-- host_total_listings_count: double (nullable = true)\n",
      " |-- host_has_profile_pic: string (nullable = true)\n",
      " |-- host_identity_verified: string (nullable = true)\n",
      " |-- room_type: string (nullable = true)\n",
      " |-- accommodates: double (nullable = true)\n",
      " |-- bathrooms: double (nullable = true)\n",
      " |-- bedrooms: double (nullable = true)\n",
      " |-- beds: double (nullable = true)\n",
      " |-- price: double (nullable = true)\n",
      " |-- number_of_reviews_ltm: double (nullable = true)\n",
      " |-- review_scores_rating: double (nullable = true)\n",
      " |-- review_scores_accuracy: double (nullable = true)\n",
      " |-- review_scores_cleanliness: double (nullable = true)\n",
      " |-- review_scores_checkin: double (nullable = true)\n",
      " |-- review_scores_communication: double (nullable = true)\n",
      " |-- review_scores_location: double (nullable = true)\n",
      " |-- review_scores_value: double (nullable = true)\n",
      " |-- instant_bookable: string (nullable = true)\n",
      " |-- cancellation_policy: string (nullable = true)\n",
      " |-- require_guest_profile_picture: string (nullable = true)\n",
      " |-- require_guest_phone_verification: string (nullable = true)\n",
      " |-- calculated_host_listings_count: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'host_is_superhost': 0,\n",
       " 'host_total_listings_count': 0,\n",
       " 'host_has_profile_pic': 0,\n",
       " 'host_identity_verified': 0,\n",
       " 'room_type': 0,\n",
       " 'accommodates': 0,\n",
       " 'bathrooms': 21,\n",
       " 'bedrooms': 2,\n",
       " 'beds': 7,\n",
       " 'price': 0,\n",
       " 'number_of_reviews_ltm': 0,\n",
       " 'review_scores_rating': 1421,\n",
       " 'review_scores_accuracy': 1425,\n",
       " 'review_scores_cleanliness': 1424,\n",
       " 'review_scores_checkin': 1427,\n",
       " 'review_scores_communication': 1423,\n",
       " 'review_scores_location': 1427,\n",
       " 'review_scores_value': 1428,\n",
       " 'instant_bookable': 0,\n",
       " 'cancellation_policy': 0,\n",
       " 'require_guest_profile_picture': 0,\n",
       " 'require_guest_phone_verification': 0,\n",
       " 'calculated_host_listings_count': 0}"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Null value check\n",
    "null_dict = dict()\n",
    "\n",
    "for col in df.columns:\n",
    "    null_dict[col] = df.select(col).where(F.col(col).isNull()).count()\n",
    "    \n",
    "null_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "For the future purpose\n",
    "select columns with a string type\n",
    "select columns with a numerical type (in this case, double type)\n",
    "'''\n",
    "\n",
    "cat_cols = [field for (field, dataType) in df.dtypes if dataType == 'string']\n",
    "num_cols = [field for (field, dataType) in df.dtypes if ((dataType=='double') & (field !='price'))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Dealing with null values : Here, I will use Imputer for numerical features with means.</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imputer\n",
    "from pyspark.ml.feature import Imputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer = Imputer(inputCols=num_cols, outputCols=num_cols)\n",
    "\n",
    "imputed_df = imputer.fit(df).transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'host_is_superhost': 0,\n",
       " 'host_total_listings_count': 0,\n",
       " 'host_has_profile_pic': 0,\n",
       " 'host_identity_verified': 0,\n",
       " 'room_type': 0,\n",
       " 'accommodates': 0,\n",
       " 'bathrooms': 0,\n",
       " 'bedrooms': 0,\n",
       " 'beds': 0,\n",
       " 'price': 0,\n",
       " 'number_of_reviews_ltm': 0,\n",
       " 'review_scores_rating': 0,\n",
       " 'review_scores_accuracy': 0,\n",
       " 'review_scores_cleanliness': 0,\n",
       " 'review_scores_checkin': 0,\n",
       " 'review_scores_communication': 0,\n",
       " 'review_scores_location': 0,\n",
       " 'review_scores_value': 0,\n",
       " 'instant_bookable': 0,\n",
       " 'cancellation_policy': 0,\n",
       " 'require_guest_profile_picture': 0,\n",
       " 'require_guest_phone_verification': 0,\n",
       " 'calculated_host_listings_count': 0}"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Null value check\n",
    "null_dict = dict()\n",
    "\n",
    "for col in imputed_df.columns:\n",
    "    null_dict[col] = imputed_df.select(col).where(F.col(col).isNull()).count()\n",
    "    \n",
    "null_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 5784 rows in the training set, and 1367 in the test set\n"
     ]
    }
   ],
   "source": [
    "# Creating Training and Test Data sets\n",
    "trainDF, testDF = imputed_df.randomSplit([0.8, 0.2], seed = 42)\n",
    "\n",
    "print(f'There are {trainDF.count()} rows in the training set, and {testDF.count()} in the test set')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Build Simple Pipeline: Vectorassembler + linear Regression</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----+---------+-----+\n",
      "|bedrooms|beds| features|price|\n",
      "+--------+----+---------+-----+\n",
      "|     1.0| 1.0|[1.0,1.0]|200.0|\n",
      "|     2.0| 2.0|[2.0,2.0]|199.0|\n",
      "|     3.0| 3.0|[3.0,3.0]|750.0|\n",
      "|     1.0| 1.0|[1.0,1.0]|194.0|\n",
      "|     0.0| 1.0|[0.0,1.0]| 60.0|\n",
      "+--------+----+---------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Preparing features with transformers\n",
    "\n",
    "vecAssembler = VectorAssembler(inputCols=['bedrooms', 'beds'], outputCol='features')\n",
    "\n",
    "# To see the result of vector assembler\n",
    "vecTrainDF = vecAssembler.transform(trainDF)\n",
    "vecTrainDF.select('bedrooms', 'beds', 'features', 'price').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Regression with MLlib\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "\n",
    "lr = LinearRegression(featuresCol='features', labelCol='price')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a Pipeline\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "pipeline = Pipeline(stages=[vecAssembler, lr])\n",
    "pipelineModel = pipeline.fit(trainDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----+\n",
      "|bedrooms|beds|\n",
      "+--------+----+\n",
      "|     3.0| 3.0|\n",
      "|     0.0| 1.0|\n",
      "|     1.0| 1.0|\n",
      "|     0.0| 1.0|\n",
      "|     0.0| 1.0|\n",
      "+--------+----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "testDF.select('bedrooms', 'beds').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+------------------+\n",
      "| features|price|        prediction|\n",
      "+---------+-----+------------------+\n",
      "|[3.0,3.0]|300.0|405.92479213858223|\n",
      "|[0.0,1.0]| 88.0| 64.44509135229788|\n",
      "|[1.0,1.0]| 75.0|160.30399613836227|\n",
      "|[0.0,1.0]| 95.0| 64.44509135229788|\n",
      "|[0.0,1.0]|112.0| 64.44509135229788|\n",
      "|[0.0,1.0]|115.0| 64.44509135229788|\n",
      "|[0.0,1.0]|140.0| 64.44509135229788|\n",
      "|[0.0,1.0]|200.0| 64.44509135229788|\n",
      "|[1.0,1.0]| 89.0|160.30399613836227|\n",
      "|[1.0,1.0]| 90.0|160.30399613836227|\n",
      "+---------+-----+------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# make a prediction\n",
    "predDF = pipelineModel.transform(testDF)\n",
    "\n",
    "predDF.select('features', 'price', 'prediction').show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE is 313.71548371860786\n"
     ]
    }
   ],
   "source": [
    "# Evaluate our model\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "regressionEvaluator = RegressionEvaluator(\n",
    "                        predictionCol = 'prediction',\n",
    "                        labelCol = 'price',\n",
    "                        metricName = 'rmse'\n",
    "                        )\n",
    "\n",
    "rmse = regressionEvaluator.evaluate(predDF)\n",
    "\n",
    "\n",
    "print(f'RMSE is {rmse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|summary|             price|\n",
      "+-------+------------------+\n",
      "|  count|              7151|\n",
      "|   mean| 213.6540344007831|\n",
      "| stddev|313.28222046853125|\n",
      "|    min|               0.0|\n",
      "|    25%|             100.0|\n",
      "|    50%|             150.0|\n",
      "|    75%|           10000.0|\n",
      "|    max|           10000.0|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('price').summary().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f11a26717f0>"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAEGCAYAAABPdROvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAaJklEQVR4nO3df5DU9Z3n8eeLmRFGwIiABBkM7kK5JwmS2MXqkfK2YjaSTU68GBNy58LtWceVZ27V2z2jqdTtbmqvKlopd2Pq9JYzRkiy4fDHBXYvJiHgJZdd/DFElCBxndUIAwRGRAWFcYZ53x/9nbVn6IZuv9P9pb/9elR1dff7+/32vL8h9qu/n+8vRQRmZmbv1risGzAzs+bmIDEzs1QcJGZmloqDxMzMUnGQmJlZKu1ZN9Bo06ZNizlz5mTdhplZU9m6desrETG93LSWC5I5c+bQ3d2ddRtmZk1F0suVpnloy8zMUnGQmJlZKg4SMzNLxUFiZmapOEjMzCyVugWJpPslHZD0i5LaOZI2SnoheZ5SMu12ST2Snpd0ZUn9Eknbk2l3S1JSHy/pfyX1JyTNqde6WOs4eKSfZ3a/xsEj/Vm3YtY06rlF8gCwZFTtNmBTRMwDNiXvkXQRsAyYnyxzj6S2ZJl7gZXAvOQx/JnXA4ciYi7wF8AddVsTawnrt+1h8R2bue6+J1h8x2Y2bNuTdUtmTaFuQRIRPwVeHVVeCqxOXq8Gri6pr42I/oh4CegBFkmaCZwVEVuieL37NaOWGf6sh4ArhrdWzGp18Eg/X3j4WY4NDHG4f5BjA0Pc+vCz3jIxq0Kj95HMiIh9AMnzuUl9FrC7ZL7epDYreT26PmKZiBgEXgemlvujklZK6pbU3dfXN0arYnnSe+goHeNG/ufQMW4cvYeOZtSRWfM4XXa2l9uSiJPUT7bMicWIVRFRiIjC9Ollz/C3Ftc1pZOBoaERtYGhIbqmdGbUkVnzaHSQ7E+Gq0ieDyT1XmB2yXxdwN6k3lWmPmIZSe3AezhxKM2sKlMnjefOaxYwoWMck8e3M6FjHHdes4Cpk8Zn3ZrZaa/R19raAKwAvpI8ry+p/7Wku4DzKO5UfzIijks6LOlS4AlgOfD1UZ+1Bfg0sDl832BL4aqFs1g8dxq9h47SNaXTIWJWpboFiaTvAr8DTJPUC/wJxQBZJ+l6YBdwLUBE7JC0DngOGARujIjjyUfdQPEIsE7g0eQB8A3gW5J6KG6JLKvXuljrmDppvAPErEZqtR/xhUIhfPVfM7PaSNoaEYVy006Xne1mZtakHCRmZpaKg8TMzFJxkJiZWSoOEjMzS8VBYmZmqThIzMwsFQeJmZml4iAxM7NUHCRmZpaKg8TMzFJxkJiZWSoOEjMzS8VBYmZmqThIzMwsFQeJmZml4iAxM7NUHCRmZpaKg8TMzFJxkJiZWSoOEjMzS8VBYmZmqThIzMwsFQeJmZml4iAxM7NUHCRmZpaKg8TMzFJxkJiZWSoOEjMzS8VBYmZmqThIzMwslUyCRNItknZI+oWk70qaIOkcSRslvZA8TymZ/3ZJPZKel3RlSf0SSduTaXdLUhbrY2bWyhoeJJJmAX8IFCLi/UAbsAy4DdgUEfOATcl7JF2UTJ8PLAHukdSWfNy9wEpgXvJY0sBVMTMzshvaagc6JbUDZwJ7gaXA6mT6auDq5PVSYG1E9EfES0APsEjSTOCsiNgSEQGsKVnGzMwapOFBEhF7gK8Cu4B9wOsR8SNgRkTsS+bZB5ybLDIL2F3yEb1JbVbyenT9BJJWSuqW1N3X1zeWq2Nm1vKyGNqaQnEr4wLgPGCipOtOtkiZWpykfmIxYlVEFCKiMH369FpbNjOzk8hiaOujwEsR0RcRA8AjwD8H9ifDVSTPB5L5e4HZJct3URwK601ej66bmVkDZREku4BLJZ2ZHGV1BbAT2ACsSOZZAaxPXm8AlkkaL+kCijvVn0yGvw5LujT5nOUly5iZWYO0N/oPRsQTkh4Cfg4MAk8Dq4BJwDpJ11MMm2uT+XdIWgc8l8x/Y0QcTz7uBuABoBN4NHmYmVkDqXjAU+soFArR3d2ddRtmZk1F0taIKJSb5jPbzcwsFQeJmZml4iAxM7NUHCRmZpaKg8TMzFJxkJiZWSoOEjMzS8VBYmZmqThIzMwsFQeJmZml4iAxM7NUHCRmZpaKg8TMzFJxkJiZWSoOEjMzS8VBYmZmqThIzMwsFQeJmZml4iAxM7NUHCRmZpaKg8TMzFJxkJiZWSoOEjMzS8VBYmZmqThIzMwsFQeJmZml4iAxM7NUHCRmZpaKg8TMzFJxkJiZWSqZBImksyU9JOmXknZKukzSOZI2SnoheZ5SMv/tknokPS/pypL6JZK2J9PulqQs1sfMrJVltUXyNeAHEfFbwMXATuA2YFNEzAM2Je+RdBGwDJgPLAHukdSWfM69wEpgXvJY0siVMDOzDIJE0lnA5cA3ACLi7Yh4DVgKrE5mWw1cnbxeCqyNiP6IeAnoARZJmgmcFRFbIiKANSXLmJlZg2SxRfIbQB/wTUlPS7pP0kRgRkTsA0iez03mnwXsLlm+N6nNSl6Prp9A0kpJ3ZK6+/r6xnZtzMxaXBZB0g58CLg3Ij4IvEkyjFVBuf0ecZL6icWIVRFRiIjC9OnTa+3XzMxOIosg6QV6I+KJ5P1DFINlfzJcRfJ8oGT+2SXLdwF7k3pXmbqZmTVQw4MkIn4N7JZ0YVK6AngO2ACsSGorgPXJ6w3AMknjJV1Acaf6k8nw12FJlyZHay0vWcbMzBqkPaO/+5+A70g6A3gR+AOKobZO0vXALuBagIjYIWkdxbAZBG6MiOPJ59wAPAB0Ao8mDzMzayAVD3hqHYVCIbq7u7Nuw8ysqUjaGhGFctN8ZruZmaXiIDEzs1QcJGZmloqDxMzMUqk6SCS9T9JHk9edkibXry0zM2sWVQWJpH9P8cTBv0pKXcD36tWUmZk1j2q3SG4EFgNvAETEC7xzLSwzM2th1QZJf0S8PfxGUjsVrmtlZmatpdog+YmkLwKdkn4XeBD4m/q1ZWZmzaLaILmN4qXftwP/Afg+8KV6NWVmZs2j2mttdQL3R8T/BEjuUNgJvFWvxszMrDlUu0WyiWJwDOsEfjz27ZiZWbOpNkgmRMSR4TfJ6zPr05KZmTWTaoPkTUkfGn4j6RLgaH1aMjOzZlLtPpKbgQclDd+BcCbw2fq0ZGZmzaSqIImIpyT9FnAhxXul/zIiBuramZmZNYWTBomkj0TEZkmfGjVpniQi4pE69mZmZk3gVFsk/wLYDPzLMtMCcJCYmbW4kwZJRPyJpHHAoxGxrkE9mZlZEznlUVsRMQR8vgG9mJlZE6r28N+Nkv5Y0mxJ5ww/6tqZmZk1hWoP//13FPeJ/MdR9d8Y23bMzKzZVBskF1EMkQ9TDJT/B/yPejVlZmbNo9ogWU3xplZ3J+8/l9Q+U4+mzMyseVQbJBdGxMUl7x+T9Ew9GjIzs+ZS7c72pyVdOvxG0m8Df1eflszMrJlUu0Xy28BySbuS9+cDOyVtByIiFtSlOzMzO+1VGyRL6tqFmZk1rWov2vhyvRsxM7PmVO0+EjMzs7IcJGZmlkpmQSKpTdLTkv42eX+OpI2SXkiep5TMe7ukHknPS7qypH6JpO3JtLslKYt1MTNrZVlukdwE7Cx5fxuwKSLmAZuS90i6CFgGzKe40/8eSW3JMvcCK4F5ycMHBZiZNVgmQSKpC/gEcF9JeSnFs+VJnq8uqa+NiP6IeAnoARZJmgmcFRFbIiKANSXLmJlZg2S1RfKXwK3AUEltRkTsA0iez03qs4DdJfP1JrVZyevR9RNIWimpW1J3X1/f2KyBmZkBGQSJpE8CByJia7WLlKnFSeonFiNWRUQhIgrTp0+v8s+amVk1qj0hcSwtBq6S9HvABOAsSd8G9kuaGRH7kmGrA8n8vcDskuW7gL1JvatM3czMGqjhWyQRcXtEdEXEHIo70TdHxHXABmBFMtsKYH3yegOwTNJ4SRdQ3Kn+ZDL8dVjSpcnRWstLljEzswbJYoukkq8A6yRdD+wCrgWIiB2S1gHPAYPAjRFxPFnmBuABoBN4NHmYmVkDqXjAU+soFArR3d2ddRtmZk1F0taIKJSb5jPbzcwsFQeJmZml4iAxM7NUHCRm1nIOHunnmd2vcfBIf9at5MLpdNSWmVndrd+2hy88/Cwd48YxMDTEndcs4KqFZS+KYVXyFomZtYyDR/r5wsPPcmxgiMP9gxwbGOLWh5/1lklKDhIzaxm9h47SMW7k117HuHH0HjqaUUf54CAxs5bRNaWTgaGhEbWBoSG6pnRm1FE+OEjMrGVMnTSeO69ZwISOcUwe386EjnHcec0Cpk4an3VrTc07282spVy1cBaL506j99BRuqZ0OkTGgIPEzFrO1EnjHSBjyENbZmaWioPEzMxScZCYmVkqDhIzM0vFQWJmZqk4SMzMLBUHiZmZpeIgMTOzVBwkZmaWioPEzMxScZCYWcvxHRLHlq+1ZWYtxXdIHHveIjGzluE7JNaHg8TMWobvkFgfDhIzaxm+Q2J9OEjMrGX4Don14Z3tZtZSfIfEsecgMbOW4zskji0PbZmZWSoNDxJJsyU9JmmnpB2Sbkrq50jaKOmF5HlKyTK3S+qR9LykK0vql0janky7W5IavT555pO2zKwaWWyRDAJ/FBH/DLgUuFHSRcBtwKaImAdsSt6TTFsGzAeWAPdIaks+615gJTAveSxp5Irk2fpte1h8x2auu+8JFt+xmQ3b9mTdkpmdphoeJBGxLyJ+nrw+DOwEZgFLgdXJbKuBq5PXS4G1EdEfES8BPcAiSTOBsyJiS0QEsKZkGUvBJ22ZWS0y3UciaQ7wQeAJYEZE7INi2ADnJrPNAnaXLNab1GYlr0fXy/2dlZK6JXX39fWN5Srkkk/asrzzsO3YyuyoLUmTgIeBmyPijZPs3ig3IU5SP7EYsQpYBVAoFMrOY+/wSVuWZ77W1tjLZItEUgfFEPlORDySlPcnw1UkzweSei8wu2TxLmBvUu8qU7eUfNKW5ZWHbeuj4VskyZFV3wB2RsRdJZM2ACuAryTP60vqfy3pLuA8ijvVn4yI45IOS7qU4tDYcuDrDVqN3PNJW5ZHw8O2x3hni3t42Nb/H3/3shjaWgz8PrBd0rak9kWKAbJO0vXALuBagIjYIWkd8BzFI75ujIjjyXI3AA8AncCjycPGiE/asrzxsG19qHjAU+soFArR3d2ddRtmlpEN2/Zwq/eR1EzS1ogolJvmS6SYWUvxsO3Yc5CYWcvxsO3Y8rW2zMwsFQeJmZml4iAxM7NUHCRmLc6XC7G0vLPdrIWt37aH//LgNsQ4giG+eu1CHwprNfMWiVXkX6r5dvBIPzev3cbbx6H/+BBvH4eb1m7zv7fVzFskVpYvbJd/W/7x4AlXOY2k/smLz8uiJWtS3iKxE/jCdq3hlSPHaqqbVeIgsRP4fiSt4cNzp9dUzxMP244tD23ZCbqmdHJs8PiI2rHB4y1xYbue/YfZtvs1Fs4+m7kzJmfdTl3NnTGZ5Zedz5otu/6ptvyy83O/3h62HXsOEitr9MU8W+Hinv/1e9tZ8/jIL9UvL/1Ahh01QP7/WUcoHbYdvpT8rQ8/y+K503zJlBQ8tGUn6D10lM6Okb8xOjvacz201bP/8IgQAVizZRc9+w9n1FH9teI6e9i2PhwkdoKuKZ0c6R8cUTvSP5jroa1tu1+rqZ4HP+t5paZ6Hvh+JPXhILETHHrz7bKHhR568+0s2mmIhbPPrqmeB9MmnVFTPQ+GbyM9vl2c2dHG+Hb5NtJjwEFiJ2jFX+dTJp5B2ziNqLWNE1Mm5vdL9bLfnFZTPS+KP5LEUASgk89sVXGQVKmVDhdsxV/nvYeO0tE28kulo025Hzsf/TWa96/Vg0f6+eMHn6F/cIhjg0P0Dw7xRw8+0xL/XdeTg6QK67ftYfEdm7nuvidYfMdmNmzbk3VLdVXpV3ief51PPKONYwMjx86PDQwx8Yy2jDqqvy3/+EqFM9vzu49kx97XGTg+cq0Hjgc79r6eUUf54CA5hVY8y3vH3jdqqufBU796taZ6Hmx9+VBN9XyotM2V922x+o6qOEhOoTUPF6x0ckF+Tzr4+wpHKlWq58HA8aGa6nlw3nsm1FTPi3qPqjhITqEVDxc8s6P8cE6leh70jzqT/1T1PCi8b0pN9TzY+3r564hVqudBI0ZVHCSnMHXSeD5T6BpR+0yhK9eHC/6iwnhxpXoetLeVH9qoVM+Dn/xDX031PHj65fJDlZXqedCIURUHySkcPNLPuu7eEbV13b253keypedgTfU86DnwZk31PHj8xfJfnpXqebDz1+XP2q9Uz4OuKZ0cHRh5gvHRgbE9wdhBcgqtuI/k6Qrni1Sq58GrFU62rFTPgzeOlv8xVKmeB9MrjCRUqueFpJO+T8tBcgqNSPPTzTlndtRUz4NWPJbn2EBt9TzY9epbNdXzoPfQUSa0j9y/OaG9zUNbjVbvND/dvPX2YE31POh7s/y3Z6V6HlQ6jCC/hxfAr18v/+VZqZ4HjThgyEFyCr2HjpY9gSnPQ1u7Xis/tFGpbtYspk4sP4RVqZ4Hw9cXm9Axjsnj25nQMW7Mry/m+5Gcwrf+/sWK9Ys/+6EGd2NmacyocL5IpXpeXLVwFovnTqP30FG6pnSO+VGn3iI5hYee3ldT3cxOXxPHl//tXKmeJ1Mnjefi2WfX5dQFB4lZi6p0eml+TzuFwvvKX3i0Ut2q0/RBImmJpOcl9Ui6Let+zJpFK36pDla4+kululWnqYNEUhvw34GPAxcBn5N0UbZdmTWHee89q6Z6HrTiLRIaoamDBFgE9ETEixHxNrAWWJpxT9aEFpw3uaZ6Hsw/r3xgVKrnwdwZk1l+2fkjassvO5+5M/L779wIzR4ks4DdJe97k9oIklZK6pbU3ddX23WErlvUVVPdmtNdn/1gTfU8+Nj895a9sdXH5r83i3Ya5stLP8CPb7mcr356AT++5XK+vPQDWbfU9Jo9SMqdGXjCtc4jYlVEFCKiMH369Jr+wJ9/6uKa6nnw41sur6meB634S3XqpPF8bdlCzmgTHW3ijDbxtWULc31B0mFzZ0zm04XZuf73baRmP+atF5hd8r4L2DvWf+RXX/kEX3rkGR7dsZ+Pz5+R6xCBd75U12zZ9U+1vH+pQvGX6vJL57Bt92ssnH127tcX6n9+gbUGRTTvzYoktQP/AFwB7AGeAv51ROyotEyhUIju7u4GddjcevYfbqkvVTOrTNLWiCiUm9bUWyQRMSjp88APKR7+fv/JQsRqM3fGZAeImZ1SUwcJQER8H/h+1n2YmbWqZt/ZbmZmGXOQmJlZKg4SMzNLxUFiZmapNPXhv++GpD7g5Xe5+DTglTFspxl4nVuD17k1pFnn90VE2TO6Wy5I0pDUXek46rzyOrcGr3NrqNc6e2jLzMxScZCYmVkqDpLarMq6gQx4nVuD17k11GWdvY/EzMxS8RaJmZml4iAxM7NUHCRVkrRE0vOSeiTdlnU/9SbpfkkHJP0i614aRdJsSY9J2ilph6Sbsu6pniRNkPSkpGeS9f2zrHtqFEltkp6W9LdZ99IIkn4labukbZLG/D4a3kdSBUltFO978rsUb6b1FPC5iHgu08bqSNLlwBFgTUS8P+t+GkHSTGBmRPxc0mRgK3B1Xv+dJQmYGBFHJHUAPwNuiojHM26t7iT9Z6AAnBURn8y6n3qT9CugEBF1OQHTWyTVWQT0RMSLEfE2sBZYmnFPdRURPwVezbqPRoqIfRHx8+T1YWAnMCvbruonio4kbzuSR+5/WUrqAj4B3Jd1L3nhIKnOLGB3yftecvwFYyBpDvBB4IlsO6mvZIhnG3AA2BgRuV7fxF8CtwJDWTfSQAH8SNJWSSvH+sMdJNVRmVruf7m1KkmTgIeBmyPijaz7qaeIOB4RC4EuYJGkXA9jSvokcCAitmbdS4MtjogPAR8HbkyGrseMg6Q6vcDskvddwN6MerE6SvYVPAx8JyIeybqfRomI14D/CyzJuJV6WwxclewzWAt8RNK3s22p/iJib/J8APjfFIfrx4yDpDpPAfMkXSDpDGAZsCHjnmyMJTufvwHsjIi7su6n3iRNl3R28roT+Cjwy2y7qq+IuD0iuiJiDsX/jjdHxHUZt1VXkiYmB48gaSLwMWBMj8Z0kFQhIgaBzwM/pLgDdl1E7Mi2q/qS9F1gC3ChpF5J12fdUwMsBn6f4q/Ubcnj97Juqo5mAo9Jepbij6WNEdESh8O2mBnAzyQ9AzwJ/J+I+MFY/gEf/mtmZql4i8TMzFJxkJiZWSoOEjMzS8VBYmZmqThIzMwsFQeJWQ0kzXm3V0ROs6zZ6cxBYpYxSe1Z92CWhoPErHbtklZLelbSQ5LOlHSJpJ8kF8X7YXJJepL6M5K2ADcOf4CkfyvpQUl/Q/FieudI+l7ymY9LWpDMV6n+p0kPP0ruNfEpSXcm95z4QXKpFyR9RdJzyfJfbfz/VNYKHCRmtbsQWBURC4A3KAbE14FPR8QlwP3Af0vm/SbwhxFxWZnPuQxYEREfAf4MeDr5zC8Ca5J5KtUBfpPi5dCXAt8GHouIDwBHgU9IOgf4V8D8ZPk/H5O1NxvFQWJWu90R8XfJ628DVwLvBzYml2T/EtAl6T3A2RHxk2Teb436nI0RMXzPlw8PT4+IzcDUZPlKdYBHI2IA2A60AcOXvdgOzKEYcseA+yR9CnhrLFbebDSPzZrVbvR1hQ4DO0ZvdSQXRDzZNYjeLJ29wt852S0M+gEiYkjSQLxzvaMhoD0iBiUtAq6geIHCzwMfOUk/Zu+Kt0jMane+pOHQ+BzwODB9uCapQ9L85NLsr0v6cDLvvznJZ/50eLqk3wFeSe6FUql+Ssl9Vd4TEd8HbgYWVr+KZtXzFolZ7XYCKyT9FfACxf0jPwTuToad2inehW8H8AfA/ZLeSuap5E+BbyZX4n0LWHGKejUmA+slTaC4ZXNLDcuaVc1X/zUzs1Q8tGVmZqk4SMzMLBUHiZmZpeIgMTOzVBwkZmaWioPEzMxScZCYmVkq/x/Rx9ZdkjwN+AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "bed_price_df = testDF.select('bedrooms', 'price').toPandas()\n",
    "bed_price_df.plot.scatter('bedrooms', 'price')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------+\n",
      "|bedrooms|  price|\n",
      "+--------+-------+\n",
      "|     2.0|10000.0|\n",
      "+--------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# We have outlier here\n",
    "# I am curious what happens if I delete that outlier\n",
    "# Linear regression is basically weak to outliers\n",
    "\n",
    "testDF.select('bedrooms', 'price').where(testDF.price > 8000).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_testDF = testDF.filter(testDF.price < 8000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+------------------+\n",
      "| features|price|        prediction|\n",
      "+---------+-----+------------------+\n",
      "|[3.0,3.0]|300.0|405.92479213858223|\n",
      "|[0.0,1.0]| 88.0| 64.44509135229788|\n",
      "|[1.0,1.0]| 75.0|160.30399613836227|\n",
      "|[0.0,1.0]| 95.0| 64.44509135229788|\n",
      "|[0.0,1.0]|112.0| 64.44509135229788|\n",
      "+---------+-----+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# make a prediction\n",
    "predDF = pipelineModel.transform(test_testDF)\n",
    "\n",
    "predDF.select('features', 'price', 'prediction').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE is 174.68544495844938\n"
     ]
    }
   ],
   "source": [
    "# Evaluate our model\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "regressionEvaluator = RegressionEvaluator(\n",
    "                        predictionCol = 'prediction',\n",
    "                        labelCol = 'price',\n",
    "                        metricName = 'rmse'\n",
    "                        )\n",
    "\n",
    "rmse = regressionEvaluator.evaluate(predDF)\n",
    "\n",
    "\n",
    "print(f'RMSE is {rmse}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>We can see that one outlier lower the performance of a regression model</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Test of dropping null values instead of imputing with mean</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "droped_df = df.dropna(subset=('bedrooms', 'bathrooms', 'beds'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 5784 rows in the training set, and 1367 in the test set\n"
     ]
    }
   ],
   "source": [
    "# Creating Training and Test Data sets\n",
    "d_trainDF, d_testDF = imputed_df.randomSplit([0.8, 0.2], seed = 42)\n",
    "\n",
    "print(f'There are {d_trainDF.count()} rows in the training set, and {d_testDF.count()} in the test set')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------+--------+-----+\n",
      "|bedrooms|bathrooms|features|price|\n",
      "+--------+---------+--------+-----+\n",
      "|     1.0|      1.0|   [1.0]|200.0|\n",
      "|     2.0|      2.0|   [2.0]|199.0|\n",
      "|     3.0|      1.5|   [3.0]|750.0|\n",
      "|     1.0|      0.5|   [1.0]|194.0|\n",
      "|     0.0|      1.0|   [0.0]| 60.0|\n",
      "+--------+---------+--------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Preparing features with transformers\n",
    "\n",
    "d_vecAssembler = VectorAssembler(inputCols=['bedrooms'], outputCol='features')\n",
    "\n",
    "# To see the result of vector assembler\n",
    "d_vecTrainDF = d_vecAssembler.transform(d_trainDF)\n",
    "d_vecTrainDF.select('bedrooms', 'bathrooms', 'features', 'price').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Regression with MLlib\n",
    "\n",
    "d_lr = LinearRegression(featuresCol='features', labelCol='price')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_pipeline = Pipeline(stages=[d_vecAssembler, d_lr])\n",
    "d_pipelineModel = d_pipeline.fit(trainDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+------------------+\n",
      "|features|price|        prediction|\n",
      "+--------+-----+------------------+\n",
      "|   [3.0]|300.0| 414.5102931306073|\n",
      "|   [0.0]| 88.0|51.081508941708364|\n",
      "|   [1.0]| 75.0|172.22443700467468|\n",
      "|   [0.0]| 95.0|51.081508941708364|\n",
      "|   [0.0]|112.0|51.081508941708364|\n",
      "+--------+-----+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# make a prediction\n",
    "d_predDF = d_pipelineModel.transform(d_testDF)\n",
    "\n",
    "d_predDF.select('features', 'price', 'prediction').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE is 315.279104840011\n"
     ]
    }
   ],
   "source": [
    "d_regressionEvaluator = RegressionEvaluator(\n",
    "                        predictionCol = 'prediction',\n",
    "                        labelCol = 'price',\n",
    "                        metricName = 'rmse'\n",
    "                        )\n",
    "\n",
    "d_rmse = regressionEvaluator.evaluate(d_predDF)\n",
    "\n",
    "\n",
    "print(f'RMSE is {d_rmse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This does not improve my model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Test End</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build a pipeline with whole variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "1. categorical columns: use StringIndexer to change string values to numerical values\n",
    "2. numerical columns: use StandardScaler to normalize each feature\n",
    "'''\n",
    "\n",
    "from pyspark.ml.feature import StringIndexer, StandardScaler, VectorAssembler\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "# index column to use for StringIndexer\n",
    "index_cols = [col + '_idx' for col in cat_cols]\n",
    "# scaler column to use for StandardScaler\n",
    "scaled_cols = [col +'scaled' for col in num_cols]\n",
    "\n",
    "# StringIndexer\n",
    "stringIndexer = StringIndexer(inputCols=cat_cols, outputCols=index_cols, handleInvalid='skip')\n",
    "\n",
    "\n",
    "assemblerinput = index_cols + num_cols\n",
    "\n",
    "# Vector Assembler \n",
    "# : combines a given list of columns into a single vector column\n",
    "vectorassembler = VectorAssembler(inputCols= assemblerinput, outputCol = 'features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(stages=[stringIndexer] + [vectorassembler, lr])\n",
    "\n",
    "pipelinemodel = pipeline.fit(trainDF)\n",
    "\n",
    "transformed_df = pipelinemodel.transform(trainDF).select('features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+------------------+\n",
      "|            features|price|        prediction|\n",
      "+--------------------+-----+------------------+\n",
      "|[0.0,1.0,1.0,0.0,...|300.0|395.52140314661875|\n",
      "|[0.0,0.0,1.0,0.0,...| 88.0| 96.07741743093254|\n",
      "|[0.0,0.0,1.0,0.0,...| 75.0|144.00722502266694|\n",
      "|[0.0,0.0,1.0,0.0,...| 95.0| 99.58956709605081|\n",
      "|[0.0,0.0,1.0,0.0,...|112.0| 65.20471975679345|\n",
      "+--------------------+-----+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Make a prediction\n",
    "\n",
    "predDF = pipelinemodel.transform(testDF)\n",
    "\n",
    "predDF.select('features', 'price', 'prediction').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE is 308.933481062648\n",
      "MAE is 95439.8957214855\n",
      "R2 is 0.131640883814381\n"
     ]
    }
   ],
   "source": [
    "regressionEvaluator = RegressionEvaluator(\n",
    "                        predictionCol = 'prediction',\n",
    "                        labelCol = 'price',\n",
    "                        metricName = 'rmse'\n",
    "                        )\n",
    "\n",
    "# Root mean square Error\n",
    "rmse = regressionEvaluator.evaluate(predDF)\n",
    "# Mean Absolute Error\n",
    "mae = regressionEvaluator.setMetricName('mse').evaluate(predDF)\n",
    "# R2\n",
    "r2 = regressionEvaluator.setMetricName('r2').evaluate(predDF)\n",
    "\n",
    "\n",
    "print(f'RMSE is {rmse}')\n",
    "print(f'MAE is {mae}')\n",
    "print(f'R2 is {r2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "279.1798621210535\n"
     ]
    }
   ],
   "source": [
    "# Compare with a training error\n",
    "pred_train = pipelinemodel.transform(trainDF)\n",
    "rmse_train = regressionEvaluator.setMetricName('rmse').evaluate(pred_train)\n",
    "\n",
    "print(rmse_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "# StandardScaler\n",
    "standardscaler = StandardScaler(inputCol='features', outputCol='scaled_features', withStd=True, withMean=False)\n",
    "\n",
    "lr = LinearRegression(featuresCol='scaled_features', labelCol='price')\n",
    "\n",
    "pipeline_w_scaler = Pipeline(stages = [stringIndexer, vectorassembler, standardscaler, lr])\n",
    "\n",
    "pipelineModel_w_scaler = pipeline_w_scaler.fit(trainDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(scaled_features=DenseVector([0.0, 0.0, 2.0194, 1.8461, 0.0, 2.395, 0.0, 0.0, 0.0, 1.034, 1.2359, 1.0596, 0.846, 0.044, 16.2332, 17.3045, 14.7337, 22.9797, 18.7166, 15.8359, 14.3313, 0.0249])),\n",
       " Row(scaled_features=SparseVector(22, {5: 1.1975, 9: 2.068, 10: 2.4719, 11: 2.1192, 12: 1.6919, 14: 16.2332, 15: 15.5741, 16: 14.7337, 17: 22.9797, 18: 16.8449, 19: 15.8359, 20: 12.8982, 21: 0.0249})),\n",
       " Row(scaled_features=DenseVector([0.0, 16.244, 2.0194, 0.0, 0.0, 2.395, 0.0, 0.0, 0.0057, 3.102, 1.8539, 3.1788, 2.5379, 0.1758, 16.2332, 17.3045, 14.7337, 22.9797, 18.7166, 15.8359, 11.465, 0.0249]))]"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipelineModel_w_scaler.transform(trainDF).select('scaled_features').head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_w_scaler = pipelineModel_w_scaler.transform(testDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE is 308.933481062616\n",
      "MAE is 95439.89572146574\n",
      "R2 is 0.13164088381456085\n"
     ]
    }
   ],
   "source": [
    "regressionEvaluator = RegressionEvaluator(\n",
    "                        predictionCol = 'prediction',\n",
    "                        labelCol = 'price',\n",
    "                        metricName = 'rmse'\n",
    "                        )\n",
    "\n",
    "# Root mean square Error\n",
    "rmse = regressionEvaluator.evaluate(pred_w_scaler )\n",
    "# Mean Absolute Error\n",
    "mae = regressionEvaluator.setMetricName('mse').evaluate(pred_w_scaler )\n",
    "# R2\n",
    "r2 = regressionEvaluator.setMetricName('r2').evaluate(pred_w_scaler )\n",
    "\n",
    "\n",
    "print(f'RMSE is {rmse}')\n",
    "print(f'MAE is {mae}')\n",
    "print(f'R2 is {r2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### End : Nothing has been improved"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ImMaxScaler\n",
    "# by default, Min=0, Max=1\n",
    "\n",
    "scaler = MinMaxScaler(inputCol='features', outputCol='scaled_features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_w_scaler = Pipeline(stages = [stringIndexer, vectorassembler, scaler, lr])\n",
    "\n",
    "pipelineModel_w_scaler = pipeline_w_scaler.fit(trainDF)\n",
    "\n",
    "pred_w_scaler = pipelineModel_w_scaler.transform(testDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(scaled_features=DenseVector([0.0, 0.0, 1.0, 0.5, 0.0, 0.4, 0.0, 0.0, 0.0, 0.0667, 0.0714, 0.0714, 0.0714, 0.0066, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0])),\n",
       " Row(scaled_features=SparseVector(22, {5: 0.2, 9: 0.2, 10: 0.1429, 11: 0.1429, 12: 0.1429, 14: 1.0, 15: 0.875, 16: 1.0, 17: 1.0, 18: 0.875, 19: 1.0, 20: 0.875})),\n",
       " Row(scaled_features=DenseVector([0.0, 1.0, 1.0, 0.0, 0.0, 0.4, 0.0, 0.0, 0.0008, 0.3333, 0.1071, 0.2143, 0.2143, 0.0263, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.75, 0.0]))]"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipelineModel_w_scaler.transform(trainDF).select('scaled_features').head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE is 308.9334810626644\n",
      "MAE is 95439.8957214956\n",
      "R2 is 0.13164088381428918\n"
     ]
    }
   ],
   "source": [
    "regressionEvaluator = RegressionEvaluator(\n",
    "                        predictionCol = 'prediction',\n",
    "                        labelCol = 'price',\n",
    "                        metricName = 'rmse'\n",
    "                        )\n",
    "\n",
    "# Root mean square Error\n",
    "rmse = regressionEvaluator.evaluate(pred_w_scaler )\n",
    "# Mean Absolute Error\n",
    "mae = regressionEvaluator.setMetricName('mse').evaluate(pred_w_scaler )\n",
    "# R2\n",
    "r2 = regressionEvaluator.setMetricName('r2').evaluate(pred_w_scaler )\n",
    "\n",
    "\n",
    "print(f'RMSE is {rmse}')\n",
    "print(f'MAE is {mae}')\n",
    "print(f'R2 is {r2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### END - Nothing has been improved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "save this dataset for future use (I do this work with other ML models)\n",
    "'''\n",
    "\n",
    "imputed_df.write.format('parquet') \\\n",
    "    .mode('overwrite') \\\n",
    "    .option('compression', 'snappy')\\\n",
    "    .save('data/sf-airbnb/imputed_parquet')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
